---
title: "Seven Shipping Principles"
author: "REWORK"
url: "https://share.snipd.com/episode/7dbc40b7-2e49-42f2-965e-aa442dcc77be"
imageUrl: "https://wsrv.nl/?url=https%3A%2F%2Fstorage.buzzsprout.com%2Fz3e8rpihv6tu8487yub5iswu6haa%3F.jpg&w=100&h=100"
publishedOn: "None"
source: "snipd"
---
# Seven Shipping Principles

![rw-book-cover](https://wsrv.nl/?url=https%3A%2F%2Fstorage.buzzsprout.com%2Fz3e8rpihv6tu8487yub5iswu6haa%3F.jpg&w=100&h=100)

## Metadata
- Author: [[REWORK]]
- Full Title: Seven Shipping Principles
- Category: #podcasts
- URL: https://share.snipd.com/episode/7dbc40b7-2e49-42f2-965e-aa442dcc77be

## Highlights
- **Shipping Good Work**
  - Ship only good work, exceeding a minimally viable product.
  - Articulating a high standard allows for rejecting subpar work.
  Transcript:
  Kimberly Rhodes
  This week, I'm going to dive into one of the write-ups on the 37 Signals website called the Seven Shipping Principles, which is our guidelines for how we ship and shape and build software At a sustainable pace is how it's written. David, I believe you wrote this, if I'm not mistaken. Let's go through some of these seven principles. We won't dive into all of them in too much detail, but a few of them I think are really important and interesting for people to hear about. The first one, we only ship good work. I think that's pretty self-explanatory, but tell us a little bit about your thoughts on that.
  David Heinemeir Hansson
  That was actually the point that motivated writing up these shipping principles in the first place. And it sounds self-evident, but it's not actually as self-evident as it sounds when you have spent weeks on something, you're out of time, and you've built something, something that You could rationalize yourself into being okay to ship. But it's not okay to ship because it's not good. And good is actually a relatively high bar. It's better than okay. We could have written, we ship okay software. Do you know what? I am sure that would actually be a high bar in some establishments, but that is not our bar. Our bar is good software. And by articulating that as the bar, it gives us permission to say no. It gives us permission to say, yes, we've spent a fair amount of time on this one feature, this cycle, but it's not good software yet. So we're not going to ship it. We're going to eat that instinct that is to always deliver something and realize occasionally, it's quite rare. I can remember only a handful of instances where we literally had to invoke this as a stop block. This is not going out because it's just not good enough. But it is also one of those things, and I think we talked about in one of the previous podcasts, that the ultimate test of we only ship good work really comes in in the 11th hour. And that was the other reason I wrote this down, is to say, do you know what? That's just facts. Good software is an all-inclusive evaluation of what you've built. It's not this little piece here, this little piece there. It's all of it, just as it's ready to go out. And that's usually when we're ready to ship or when we want to ship. It's when we've finished assembling all the pieces. So it's no wonder that that is the ultimate test for whether this should go out the door or not. And I wrote it down in part because this is the role Jason and I often play, that we are the last stop before something goes out the door. But it'd also be nice if there were more people in the organization who felt empowered because it was written down to essentially say, you know what, we need a timeout here. Maybe this brought you, for whatever reasons, just didn't come together in time, which is not a huge amount of shame. And in fact, I think a little suspiciously sometimes about our shipping rate. I think maybe our shipping rate is actually too high that you should not aim to ship 100% of all work you set out to do. You should aim to ship, I don't know, 80, 90, 95%. But there's got to be some part of it that's not good enough. Because otherwise, either you're just the best software maker that's ever been, highly unlikely, or your standards are just not where they need to be. ([Time 0:00:11](https://share.snipd.com/snip/774220d0-e3d5-4e86-b19f-becb8561e753))
- **Good vs. Viable**
  - Minimum Viable Products (MVPs) don't yield good feedback because of incompleteness.
  - Evaluate complete, smaller ideas instead of partial, half-baked versions for better insights.
  Transcript:
  Jason Fried
  Was going to add one small thing. This is like there's been a lot of discussion about MVPs and whatnot lately. I think that's one of the issues we take with MVPs, which is like minimally viable. That's too low a bar. It also is like people use it to test ideas. I saw David wrote up a nice tweet about this recently. It's like testing incomplete half-assed ideas, like isn't really going to yield you the answers that you're looking for. That's why this stuff has to be good. Because if you want to evaluate whether or not something's any good, like you have to put something out there that you think is good, not just minimally viable, because you're going To get minimally viable feedback on that, which is like not really that good either. So that's kind of the idea is that when you put something out there in the world, it also should be a complete idea. It can be a smaller idea than you initially wanted it to be, but it needs to be a complete idea and not some partial half-ass, half-version of it in a sense. ([Time 0:03:36](https://share.snipd.com/snip/95afa916-eb68-428d-9064-70aca63ca406))
- **Contextual Confidence**
  - Base your confidence level on both team and criticality of the problem.
  - Avoid uniform testing rigor; calibrate it to the potential consequences of issues.
  Transcript:
  Kimberly Rhodes
  I'm going to read the beginning of this next one, because I think it's interesting. I'm going to get your take on it. The next one is we ship when we're confident, we talk a lot about confidence and like gut reactions here on the podcast. It says the reason we do automated and exploratory testing is so we can ship work with confidence that it won't cause major problems. But exactly how much confidence is required depends both on the team and the criticality of the problem. David, to you.
  David Heinemeir Hansson
  I think this comes up often in software development circles when we talk about quantification. When we talk about we have so and so test coverage for this product. I remember once upon a time people were talking, I need 90% test coverage, which basically meant that out of all the lines of code you have in your product, all 90% of them are going to be Tested. Or they have a test ratio. We write three lines of test code for every one line of production code. That's a ratio I've heard stated in the path. And I always go like, that doesn't tell me anything. If you're writing all this sort of mechanically, I need three lines of code for every line of production code, whether what you're implementing is completely trivial and banal, or Whether you're implementing something that if there's a bug, it costs people thousands of dollars, or in the most extreme case of criticality, that someone could get seriously hurt Or worse from it. You're not dealing with the context in mind. You should apply far less ultimate rigor to something where a problem is a mere inconvenience or even perhaps an aesthetic issue versus I am losing millions or I'm putting people in Harm's way. That's what the criticality ladder is about, which I think is a great way of looking at the whole problem of confidence. Because what are you confident about? And how confident are you really? So we try to generally have confidence that it's not likely. And this is almost like burdens of proofs, right? Like are beyond reasonable doubt. That is much higher as a burden of proof than, I forget what the one below it is called, something. Preponderance of evidence. Yeah, something like that, right? In the legal world, they clarify these levels of criticality. If you're convicting someone for murder, you damn well better be sure beyond a reasonable doubt. If you're having a dispute about some contract, that's much lower criticality. We don't have to deal with it with the same rigor. We may not even need 12 peers to adjudicate this issue. And we try to still get this the same way, that so much of the work that we do falls in the middle territory. Do you know what? If it doesn't work or there's a bug, that's not great. But also, we could fix it quickly. Sometimes we work. I have pushed out plenty of fixes where, do you know what? I know there's not an issue here, which is always, by the way, Q, that there will be an issue, but the issue isn't going to be that large. And then when we tinker with, for example, what we call Queen B, which is where we do all our billing, we take a higher burden of proof here. We want to have more tests. They have to be more regimented. We want to have more reviews. But that level of ceremony needs to be proportionate to it. And what I've seen, the biggest error is to pick one protocol, one level of ceremony, and just apply it to all of it. Apply it to the trivial stuff. And now you're, there's a Danish saying of shooting sparrows with cannons. You're shooting sparrows with cannons. That's just overkill. And at the same time, that process may also be underkill if you're literally putting people in harm's way, or you could potentially lose hundreds of thousands of dollars, right? So having that sense, the fluidity of confidence, this is why I like confidence as a word. It doesn't just, it's not a numerical scale. It doesn't go like one to five. It's again, it's a gut feel. Now that takes a while to train. I see very often junior programmers come in and they want to do everything as safe as possible. And then it takes forever, right? They want to write a million tests. They want to write the five lines of test code for one line of production code. And then they're not going to be able to ship. They're not going to fit within our six-week cycles. They're going to turn a two-week project into a five-week project. And then they quickly realize, you know what? Ah, okay, all this ceremony that I was just doing because that's the protocol, I can't actually do that and accomplish what I want to accomplish. I have to now gauge things and calibrate them such that it is proportionate to the criticality. And that's where the magic happens in those trade-offs. And I also think this is where the enjoyment happens. There is nothing more frustrating than going through meaningless checklists, bullshit checklists that are just like, oh, I have to do this because that's what the chart says, right? When you're doing something that you know isn't proportionate, that you know isn't a fit for the right thing, it's just demoralizing. It feels like you're spinning your wheels and you're wasting your time. I would rather err, if anything, a little bit on the cowboy side, right? We don't build pacemakers. So we're not going to kill anyone if we make a slight mistake. So we should air a little bit on the cowboy side. Not so much that no one wants to use our damn software because it's total crap and full of bugs and they constantly run into issues. ([Time 0:04:42](https://share.snipd.com/snip/adb14a2c-e8a8-48bc-bde8-9144f6e83277))


